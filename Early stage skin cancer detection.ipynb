{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92db309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('metadata.csv')\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971593d",
   "metadata": {},
   "source": [
    "Null Value Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = ['patient_id', 'lesion_id', 'age', 'background_mother', 'background_father', 'gender', 'img_id', 'region', 'biopsed']\n",
    "\n",
    "# Filter the dataframe to exclude unwanted columns while keeping 'diagnostic' as target\n",
    "df_filtered = df.drop(columns=[col for col in columns_to_exclude if col in df.columns])\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df_filtered.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values Heatmap (Filtered Dataset)\")\n",
    "plt.savefig(\"plots/missing_values_filtered.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ec2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values\n",
    "print(\"Dataset shape before dropping null values:\", df.shape)\n",
    "df = df.dropna()\n",
    "print(\"Dataset shape after dropping null values:\", df.shape)\n",
    "print(\"\\nRemaining null values per column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Histogram of {col}\")\n",
    "    plt.savefig(f\"plots/histogram_{col}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3460930",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Histogram of {col}\")\n",
    "    plt.savefig(f\"plots/histogram_{col}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c72bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "corr = df[num_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Numerical Features\")\n",
    "plt.savefig(\"plots/correlation_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare the data for maximum accuracy\n",
    "# First, let's handle categorical variables properly\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = df_processed.select_dtypes(include=['object', 'bool']).columns\n",
    "categorical_cols = categorical_cols.drop('diagnostic')  # Remove target variable\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in df_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Feature (X) and Target (y) separation\n",
    "X = df_processed.drop(\"diagnostic\", axis=1)\n",
    "y = df_processed[\"diagnostic\"]\n",
    "\n",
    "# Encode target variable\n",
    "target_encoder = LabelEncoder()\n",
    "y_encoded = target_encoder.fit_transform(y)\n",
    "\n",
    "# Feature scaling for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Optimized train-test split for maximum accuracy\n",
    "# Using 70-30 split for better training data, stratified sampling for balanced classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Class distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Class distribution in testing set:\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "print(\"Feature columns:\", list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1710c",
   "metadata": {},
   "source": [
    "model Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "target_encoder = LabelEncoder()\n",
    "y_encoded = target_encoder.fit_transform(y)\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_encoder.classes_, \n",
    "            yticklabels=target_encoder.classes_)\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance Plot\n",
    "feature_importance = abs(log_reg.coef_[0])\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create DataFrame for easier plotting\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importance - Logistic Regression')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee74fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier with Diagram\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=4)  # limit depth for clarity\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "\n",
    "# Plot Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=X.columns, \n",
    "          class_names=[str(c) for c in set(y)], \n",
    "          filled=True, rounded=True, fontsize=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # default k=5\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Random Forest - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance = rf_model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest - Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909753ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM) with Diagram\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "le_y = LabelEncoder()\n",
    "y = le_y.fit_transform(y)\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel=\"rbf\")  # radial basis function kernel\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "# ---- Visualization with PCA (2D projection) ----\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "svm_2d = SVC(kernel=\"rbf\")\n",
    "svm_2d.fit(X_pca, y_train)\n",
    "\n",
    "# Create meshgrid\n",
    "x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                     np.linspace(y_min, y_max, 300))\n",
    "\n",
    "Z = svm_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision regions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap=plt.cm.coolwarm, edgecolors=\"k\")\n",
    "plt.title(\"SVM Decision Boundary (PCA-reduced data)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Confusion Matrix for Best Performing Model\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a 2x2 subplot layout for confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Get all model predictions for confusion matrices\n",
    "models_to_plot = ['Random Forest', 'Logistic Regression', 'SVM', 'Gradient Boosting']\n",
    "\n",
    "for idx, model_name in enumerate(models_to_plot):\n",
    "    if model_name in model_predictions:\n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(y_test, model_predictions[model_name])\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=le.classes_, yticklabels=le.classes_, \n",
    "                   ax=axes[row, col])\n",
    "        \n",
    "        axes[row, col].set_title(f'{model_name} - Confusion Matrix\\nAccuracy: {model_accuracies[model_name]:.3f}', \n",
    "                                fontsize=12, fontweight='bold')\n",
    "        axes[row, col].set_xlabel('Predicted Label')\n",
    "        axes[row, col].set_ylabel('True Label')\n",
    "\n",
    "# Hide any empty subplots\n",
    "for idx in range(len(models_to_plot), 4):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final Best Model Confusion Matrix (Larger)\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm_best = confusion_matrix(y_test, model_predictions[best_model_name])\n",
    "\n",
    "# Create detailed confusion matrix with percentages\n",
    "cm_normalized = cm_best.astype('float') / cm_best.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=le.classes_, yticklabels=le.classes_,\n",
    "           cbar_kws={'label': 'Count'})\n",
    "\n",
    "plt.title(f'Final Confusion Matrix - {best_model_name}\\nAccuracy: {model_accuracies[best_model_name]:.3f}', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix with class-wise metrics\n",
    "print(f\"\\nFinal Confusion Matrix for {best_model_name}:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_best)\n",
    "\n",
    "# Calculate per-class metrics\n",
    "print(f\"\\nPer-Class Performance Metrics:\")\n",
    "print(\"-\"*40)\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    tp = cm_best[i, i]\n",
    "    fp = cm_best[:, i].sum() - tp\n",
    "    fn = cm_best[i, :].sum() - tp\n",
    "    tn = cm_best.sum() - tp - fp - fn\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"{class_name}:\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall: {recall:.3f}\")\n",
    "    print(f\"  Specificity: {specificity:.3f}\")\n",
    "    print(f\"  True Positives: {tp}\")\n",
    "    print(f\"  False Positives: {fp}\")\n",
    "    print(f\"  False Negatives: {fn}\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 5 Models and Show Accuracy in Histogram with Annotations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features for models that need it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if name in [\"Logistic Regression\", \"KNN\", \"SVM\"]:  # need scaled data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "    results[name] = accuracy_score(y_test, preds)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Accuracies:\", results)\n",
    "\n",
    "# Plot histogram with annotations\n",
    "plt.figure(figsize=(8,6))\n",
    "bars = plt.bar(results.keys(), results.values(), color=['blue','green','orange','red','purple'])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Comparison of 5 Models\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# Annotate accuracy values on top of bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f\"{yval:.2f}\", \n",
    "             ha='center', va='bottom', fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices for All 5 Models in One Figure\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\"patient_id\", \"lesion_id\", \"img_id\"]\n",
    "df = data.drop(columns=drop_cols)\n",
    "\n",
    "# Remove rows with missing target\n",
    "df = df.dropna(subset=[\"diagnostic\"])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"diagnostic\"])\n",
    "y = df[\"diagnostic\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in X.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "le_y = LabelEncoder()\n",
    "y = le_y.fit_transform(y)\n",
    "class_names = le_y.classes_\n",
    "\n",
    "# Fill missing values with median\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features for models that need it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Plot confusion matrices in a grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    if name in [\"Logistic Regression\", \"KNN\", \"SVM\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(ax=axes[idx], cmap=\"Blues\", colorbar=False)\n",
    "    axes[idx].set_title(f\"{name}\")\n",
    "\n",
    "# Hide the last empty subplot if 5 models\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score Analysis for All Diagnostic Categories\n",
    "\n",
    "# First, let's get F1-scores for each diagnostic category (not just weighted average)\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"F1-Score Analysis by Diagnostic Category\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get unique diagnostic categories\n",
    "diagnostic_categories = sorted(np.unique(y))\n",
    "print(f\"Diagnostic Categories: {diagnostic_categories}\")\n",
    "\n",
    "# Calculate F1-scores for each category for each model\n",
    "f1_scores_by_category = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in [\"Logistic Regression\", \"KNN\", \"SVM\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for each category\n",
    "    f1_per_category = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    f1_scores_by_category[name] = f1_per_category\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    for i, category in enumerate(diagnostic_categories):\n",
    "        print(f\"  {category}: {f1_per_category[i]:.4f}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot 1: F1-Score Heatmap\n",
    "f1_df = pd.DataFrame(f1_scores_by_category, index=diagnostic_categories)\n",
    "im = ax1.imshow(f1_df.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(diagnostic_categories)):\n",
    "    for j, model in enumerate(f1_df.columns):\n",
    "        text = ax1.text(j, i, f'{f1_df.iloc[i, j]:.3f}', \n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "ax1.set_xticks(range(len(f1_df.columns)))\n",
    "ax1.set_yticks(range(len(diagnostic_categories)))\n",
    "ax1.set_xticklabels(f1_df.columns, rotation=45, ha='right')\n",
    "ax1.set_yticklabels(diagnostic_categories)\n",
    "ax1.set_title('F1-Score Heatmap by Model and Diagnostic Category', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax1, shrink=0.8)\n",
    "cbar.set_label('F1-Score', rotation=270, labelpad=15)\n",
    "\n",
    "# Plot 2: Bar Chart Comparison\n",
    "x = np.arange(len(diagnostic_categories))\n",
    "width = 0.15\n",
    "multiplier = 0\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(models)))\n",
    "\n",
    "for i, (model_name, f1_scores) in enumerate(f1_scores_by_category.items()):\n",
    "    offset = width * multiplier\n",
    "    bars = ax2.bar(x + offset, f1_scores, width, label=model_name, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    multiplier += 1\n",
    "\n",
    "ax2.set_xlabel('Diagnostic Categories', fontweight='bold')\n",
    "ax2.set_ylabel('F1-Score', fontweight='bold')\n",
    "ax2.set_title('F1-Score Comparison by Diagnostic Category', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x + width * 2)\n",
    "ax2.set_xticklabels(diagnostic_categories, rotation=45, ha='right')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nF1-Score Summary Statistics:\")\n",
    "print(\"=\" * 40)\n",
    "f1_summary = pd.DataFrame(f1_scores_by_category, index=diagnostic_categories)\n",
    "print(f\"Average F1-Score per Model:\")\n",
    "for model in f1_summary.columns:\n",
    "    avg_f1 = f1_summary[model].mean()\n",
    "    std_f1 = f1_summary[model].std()\n",
    "    print(f\"  {model}: {avg_f1:.4f} (±{std_f1:.4f})\")\n",
    "\n",
    "print(f\"\\nAverage F1-Score per Diagnostic Category:\")\n",
    "for category in f1_summary.index:\n",
    "    avg_f1 = f1_summary.loc[category].mean()\n",
    "    std_f1 = f1_summary.loc[category].std()\n",
    "    print(f\"  {category}: {avg_f1:.4f} (±{std_f1:.4f})\")\n",
    "\n",
    "# Find best performing model for each category\n",
    "print(f\"\\nBest Performing Model per Category:\")\n",
    "for category in diagnostic_categories:\n",
    "    best_model = f1_summary.loc[category].idxmax()\n",
    "    best_score = f1_summary.loc[category].max()\n",
    "    print(f\"  {category}: {best_model} (F1={best_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97950b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Analysis - Model Performance Metrics\n",
    "\n",
    "# Calculate detailed performance metrics for all models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"System Performance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store results for comparison\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in [\"Logistic Regression\", \"KNN\", \"SVM\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate loss (error rate)\n",
    "    loss = 1 - accuracy\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Loss': loss\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  Loss:      {loss:.4f} ⚠️\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(f\"\\nModel Performance Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Find best and worst performing models\n",
    "best_model = results_df['Accuracy'].idxmax()\n",
    "best_accuracy = results_df['Accuracy'].max()\n",
    "worst_model = results_df['Accuracy'].idxmin()\n",
    "worst_accuracy = results_df['Accuracy'].min()\n",
    "highest_loss = results_df['Loss'].max()\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"\\nWorst Performing Model: {worst_model}\")\n",
    "print(f\"Worst Accuracy: {worst_accuracy:.4f}\")\n",
    "print(f\"Highest Loss: {highest_loss:.4f} ⚠️\")\n",
    "\n",
    "# Highlight models with high loss (>10%)\n",
    "print(f\"\\nModels with High Loss (>10%):\")\n",
    "print(\"-\" * 30)\n",
    "high_loss_models = results_df[results_df['Loss'] > 0.1]\n",
    "if not high_loss_models.empty:\n",
    "    for model_name in high_loss_models.index:\n",
    "        loss_val = high_loss_models.loc[model_name, 'Loss']\n",
    "        print(f\"  {model_name}: {loss_val:.4f} ⚠️ HIGH LOSS\")\n",
    "else:\n",
    "    print(\"  No models with loss >10% 👍\")\n",
    "\n",
    "# Visualize performance comparison including losses\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Loss']\n",
    "colors = ['green', 'blue', 'orange', 'purple', 'red']\n",
    "x = np.arange(len(results_df.index))\n",
    "width = 0.15\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    bars = plt.bar(x + i*width, results_df[metric], width, label=metric, alpha=0.8, color=colors[i])\n",
    "    \n",
    "    # Highlight high loss values\n",
    "    if metric == 'Loss':\n",
    "        for j, bar in enumerate(bars):\n",
    "            if results_df[metric].iloc[j] > 0.1:\n",
    "                bar.set_edgecolor('red')\n",
    "                bar.set_linewidth(3)\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                        '⚠️', ha='center', va='bottom', fontsize=12, color='red')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison - System Analysis (Losses Highlighted)')\n",
    "plt.xticks(x + width*2, results_df.index, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32204e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Random Forest Performance and Feature Importance\n",
    "\n",
    "# Random Forest is particularly well-suited for this skin cancer detection task because:\n",
    "print(\"Why Random Forest is ideal for skin cancer detection:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Handles mixed data types well (numerical and categorical features)\")\n",
    "print(\"2. Robust to outliers and missing values\")\n",
    "print(\"3. Provides feature importance rankings\")\n",
    "print(\"4. Reduces overfitting through ensemble learning\")\n",
    "print(\"5. Works well with high-dimensional medical data\")\n",
    "print(\"6. No need for feature scaling\")\n",
    "print(\"7. Can capture non-linear relationships between features\")\n",
    "\n",
    "# Get the trained Random Forest model\n",
    "rf_model = models[\"Random Forest\"]\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTarget Variable: diagnostic\")\n",
    "print(\"Classes:\", class_names)\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"Class distribution:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    count = sum(y == i)\n",
    "    percentage = (count / len(y)) * 100\n",
    "    print(f\"  {class_name}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Display top 10 most important features\n",
    "print(f\"\\nTop 10 Most Important Features for Random Forest:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['feature']:<25}: {row['importance']:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importances - Random Forest Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get Random Forest predictions and probabilities\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Calculate and display Random Forest specific metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "print(f\"\\nRandom Forest Model Performance:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, rf_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d47c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
